You are an expert Python engineer working in an existing repo located at:
  /mnt/data/Chicago_Crime-main/Chicago_Crime-main

Analyze the current codebase (Dash + Plotly UI, DuckDB querying partitioned Parquet crime lake, plus existing community area dim + GeoJSON boundary ingest). Implement population + ACS demographics dimensions from the Chicago Data Portal and JOIN them onto crime data on `community_area` (int).

CURRENT REPO CONTEXT (confirm in code before editing)
- Package: chicago_crime/
- Crime lake: data/lake/crimes/year=YYYY/month=MM/day=DD/*.parquet
- Existing dims: data/dim/community_areas/community_areas.parquet and community_areas.geojson
- Existing dim ingest: chicago_crime/ingest/ingest_dimensions.py (community areas)
- Existing daily ingest script: scripts/ingest_daily.py (calls ensure_community_areas_dim then ingest crimes)
- Existing query layer: chicago_crime/analytics/queries.py
  - has _base_from_clause() that optionally LEFT JOINs community area names onto crimes

GOAL
1) Add ingestion for:
   A) Population by Community Area (dimension parquet)
   B) ACS Demographics by Community Area (dimension parquet)
2) Update the query layer so *all dashboard queries* can return joined columns:
   - population fields
   - ACS demographic fields
3) Ensure join key is `community_area` as INTEGER:
   - crimes: TRY_CAST(c.community_area AS INTEGER)
   - dims: community_area INT

IMPORTANT CONSTRAINTS
- The Dash app must NOT call Socrata live. Only ingestion does.
- Keep it correctness-first and easy to run locally + in Docker.
- Dims should be cached to disk under ./data/dim and refreshed occasionally (max-age logic like community_areas dims).
- Do NOT break the existing community areas choropleth functionality.

DATASETS TO USE (defaults, but allow override via env vars)
- ACS 5 Year Data by Community Area: t68z-cikk
  https://data.cityofchicago.org/Community-Economic-Development/ACS-5-Year-Data-by-Community-Area/t68z-cikk
- ACS 5 Year Data by Community Area - Most Recent Year: 7umk-8dtw
  https://data.cityofchicago.org/Community-Economic-Development/ACS-5-Year-Data-by-Community-Area-Most-Recent-Year/7umk-8dtw

Implementation approach:
- For POPULATION dim:
  - Prefer the “Most Recent Year” dataset (7umk-8dtw) so it’s one row per community area.
- For ACS DEMOGRAPHICS dim:
  - Prefer the “Most Recent Year” dataset (7umk-8dtw) for the same reason (stable join, one row per area).
  - Still allow switching to t68z-cikk via env if the user later wants multiple years.

Because Socrata schema can change, DO NOT hardcode column names blindly.
Instead, implement:
- a tiny schema inspection call (fetch 1 row) and infer keys using candidate lists
- plus env var overrides for the key field names

NEW/UPDATED ENV VARS (update chicago_crime/config.py and .env.example)
Add to Settings:
- ACS_MOST_RECENT_DATASET_ID default "7umk-8dtw"
- ACS_MULTIYEAR_DATASET_ID default "t68z-cikk"
- USE_ACS_MULTIYEAR default "0"  (if 1, ingest from multiyear dataset and keep only latest year per community_area for joins)
- ACS_COMMUNITY_AREA_FIELD default inferred; override supported
- ACS_YEAR_FIELD default inferred; override supported (needed only if USE_ACS_MULTIYEAR=1)
- ACS_POPULATION_FIELD default inferred; override supported
- ACS_DIM_MAX_AGE_DAYS default 30

Also add dim paths helpers:
- data/dim/population/community_area_population.parquet
- data/dim/acs_demographics/acs_demographics.parquet

INGEST IMPLEMENTATION
1) Create a new module:
   chicago_crime/ingest/ingest_acs.py

It must implement:
- ensure_population_dim(force: bool=False, max_age_days: int|None=None) -> Path
- ensure_acs_demographics_dim(force: bool=False, max_age_days: int|None=None) -> Path
- (optional) ensure_all_acs_dims(force: bool=False) -> None

Behavior:
- Cache files under ./data/dim/... and refresh if missing or older than max_age_days
- Use chicago_crime/ingest/soda_client.py to query Socrata (consistent with existing patterns)
- If soda_client does not support returning raw dict rows easily, extend it in a backwards-compatible way:
  - add method: fetch_rows(dataset_id: str, select: str|None=None, where: str|None=None, limit: int=..., offset: int=...) -> list[dict]
  - preserve existing API behavior

Schema inference:
- Implement helper to fetch one row from the chosen dataset and inspect keys.
- Infer `community_area` field:
  candidate keys include: ["community_area", "communityarea", "community_area_number", "community_area_num", "community_area_id", "community_area_no", "community_area_"]
- Infer `population` field:
  candidate keys include: ["total_population", "population", "pop", "tot_pop", "totalpop", "pop_total"]
- Infer `year` field (only for multi-year dataset):
  candidate keys include: ["year", "acs_year", "vintage", "acs_release", "period", "time_period"]

If inference fails, raise a CLEAR error listing:
- the keys found in the dataset sample row
- which env vars to set to override

Population dim output schema (ONE ROW PER community_area):
- community_area: int
- population: int
- source_dataset_id: str
- updated_at: timestamp (utc)

ACS demographics dim output schema (ONE ROW PER community_area):
- community_area: int
- (a subset of numeric demographic fields, plus optional year if USE_ACS_MULTIYEAR=1 but final stored should be latest only)
- strategy:
  - If using 7umk-8dtw most-recent dataset: keep ALL numeric columns except obviously non-demographic IDs
  - If using t68z-cikk multiyear dataset: filter to the maximum year across the dataset, then keep rows from that year only
- ALWAYS include:
  - community_area: int
  - acs_year: int|None (if available)
  - source_dataset_id: str
  - updated_at: timestamp (utc)

Implementation details for demographics dim:
- Read rows into pandas DataFrame
- Convert community_area to int
- Convert numeric-looking columns to numeric (pandas.to_numeric(errors="coerce")) but keep strings if they are true labels
- Drop columns that are all-null
- Deduplicate by community_area (keep first)
- Sort by community_area

2) Update scripts/ingest_daily.py
Currently it calls ensure_community_areas_dim() and then ingest crimes.
Update it to:
- ensure_community_areas_dim()
- ensure_population_dim()
- ensure_acs_demographics_dim()
- then ingest crimes
All dim ingests must be best-effort (catch exceptions, log warnings, proceed with crime ingest).

3) OPTIONAL: add a CLI entrypoint
- scripts/ingest_dims.py to run all dims with --force

QUERY LAYER: JOIN DIMS
Update chicago_crime/analytics/queries.py to join population + demographics dims similarly to community_areas.

Add helpers:
- _population_dim_path(), _population_dim_exists()
- _acs_dim_path(), _acs_dim_exists()

Update _base_from_clause() so it can LEFT JOIN all dims that exist.
Example approach:
- Always start from crimes read_parquet(?) as c
- Then conditionally LEFT JOIN:
  - community areas: read_parquet(?) as ca on TRY_CAST(c.community_area as INTEGER)=ca.community_area
  - population: read_parquet(?) as pop on TRY_CAST(c.community_area as INTEGER)=pop.community_area
  - acs: read_parquet(?) as acs on TRY_CAST(c.community_area as INTEGER)=acs.community_area

Return:
- from_clause string
- params list in correct order
Keep this compatible with current calling code.

Update select lists:
- filter_crimes() should return:
  - c.*
  - community_area_name
  - population
  - plus a curated set of demographics columns OR “acs.*”
Recommendation:
- Select “acs.* EXCLUDE (community_area)” to avoid duplicate community_area columns (DuckDB supports EXCLUDE).
- Similarly for pop: select pop.population as population
If EXCLUDE is problematic, explicitly list columns by reading schema once at startup; but prefer EXCLUDE if DuckDB version supports it.

Also update any aggregations that use community_area_name_expr to still work.

IMPORTANT:
- If dim file missing, query must still work (return NULL columns for that dim).
- Do not degrade performance significantly; dims are tiny (77 rows) so join is cheap.

APP LAYER
No major UI change required for this prompt, but ensure that:
- CSV download includes population + demographics columns (since filter_crimes will now include them)
- If the app has any table preview, it should show community_area_name + population (nice-to-have)

TESTS
Add tests under tests/:
1) tests/test_population_dim_join.py
   - Create a tiny crimes parquet (2 rows) with community_area values
   - Create a population dim parquet with matching community_area and population
   - Ensure filter_crimes returns a population column joined correctly

2) tests/test_acs_dim_join.py
   - Create tiny crimes parquet + tiny demographics parquet (e.g., median_household_income, pct_poverty)
   - Ensure filter_crimes returns those columns joined correctly

Keep tests self-contained using tmp_path and write parquet with pandas/pyarrow.

DOCKER
- docker-compose already mounts ./data; ensure dims persist across restarts.
- No changes required unless paths are inconsistent.

DELIVERABLES
- Implement all code changes, update .env.example with new vars, update README with:
  - Which datasets are used (7umk-8dtw, t68z-cikk)
  - How to force refresh dims
  - How joins work

QUALITY BAR
- Code runs end-to-end.
- Clear logging and error messages for schema inference.
- Joins use community_area as INTEGER.
- Existing choropleth + community area name features remain intact.
- No TODO placeholders.

Now implement the changes in the repo, producing all new/updated files with correct imports and runnable behavior.