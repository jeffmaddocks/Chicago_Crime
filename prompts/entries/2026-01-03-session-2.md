You are an expert Python engineer working inside an existing repo named Chicago_Crime (Dash + Plotly UI, DuckDB over partitioned parquet lake). Extend the project so the dashboard can render a TRUE CHOROPLETH by Chicago Community Area, using GeoJSON boundaries from the Chicago Data Portal, and also render community area NAMES everywhere.

AUTHORITATIVE DATA SOURCES
1) Community Area boundaries + names dataset (current):
   - “Boundaries – Community Areas (current)” Socrata view id: cauq-8yn6.
2) GeoJSON export endpoint for Socrata geospatial datasets:
   - https://data.cityofchicago.org/api/geospatial/cauq-8yn6?method=export&format=GeoJSON
   (This returns GeoJSON suitable for polygon choropleths.)
3) Socrata GeoJSON response semantics:
   - GeoJSON format returns a FeatureCollection where geometry is in `geometry` and attributes are in `properties`.

GOALS
A) Pull and cache BOTH:
   1) a dimension parquet with (community_area -> community_area_name)
   2) a GeoJSON file containing the polygons, where each feature contains a stable ID that matches the crimes `community_area`
B) Update query layer to JOIN community_area_name
C) Update Dash app to render a choropleth by community area (counts, and optionally arrest rate) using Plotly
D) Provide a UI toggle:
   - Points map (scatter) for small date ranges
   - Choropleth map for large date ranges / large row counts

PROJECT CONTEXT / CURRENT ASSUMPTIONS
- Repo already ingests crimes into partitioned parquet by year/month/day:
    data/lake/crimes/year=YYYY/month=MM/day=DD/*.parquet
- DuckDB is used to query parquet.
- Existing code includes:
  - chicago_crime/ingest/soda_client.py (Socrata client)
  - chicago_crime/analytics/queries.py (DuckDB SQL queries)
  - Dash app under chicago_crime/app/*

NEW / UPDATED FILES (create/update as needed)
- chicago_crime/config.py (add new env vars)
- chicago_crime/ingest/ingest_dimensions.py (dimension + geojson ingest)
- chicago_crime/analytics/geo.py (helpers to load geojson + join keys)
- chicago_crime/analytics/queries.py (join names + new choropleth aggregations)
- chicago_crime/app/layout.py (add map mode toggle)
- chicago_crime/app/callbacks.py (render choropleth + fallback logic)
- tests/test_dim_ingest.py
- tests/test_geojson_join_key.py
- tests/test_choropleth_agg.py
- README.md (document how geojson caching works)

CONFIGURATION (ENV VARS with defaults)
Add to config.py and .env.example:
- COMMUNITY_AREAS_DATASET_ID="cauq-8yn6"
- COMMUNITY_AREAS_GEOJSON_URL default:
    "https://data.cityofchicago.org/api/geospatial/cauq-8yn6?method=export&format=GeoJSON"
- COMMUNITY_AREA_NUMBER_FIELD default "area_num_1"   (from properties)
- COMMUNITY_AREA_NAME_FIELD default "community"      (from properties)
- DIM_MAX_AGE_DAYS default 30
- MAP_MODE_DEFAULT="auto" (auto|points|choropleth)
- CHOROPLETH_METRIC_DEFAULT="count" (count|arrest_rate)
- MAP_MAX_DAYS_POINTS default 90
- MAX_MAP_POINTS default 25000

DATA STORAGE (DIMENSION + GEOJSON)
Persist under ./data (mounted in Docker):
- data/dim/community_areas/
    community_areas.parquet     # lookup table: community_area int, community_area_name str
    community_areas.geojson     # polygons with matching join key

INGEST: COMMUNITY AREA DIM + GEOJSON
Implement chicago_crime/ingest/ingest_dimensions.py:

1) ensure_community_areas_geojson(force: bool=False, max_age_days: int=30) -> pathlib.Path
   - If geojson file missing OR older than max_age_days OR force=True:
     - Download from COMMUNITY_AREAS_GEOJSON_URL with requests (stream to disk)
     - Validate it is valid GeoJSON FeatureCollection and features exist
     - Save atomically (write temp then replace)
   - Return path to geojson file.

2) extract_dim_from_geojson(geojson_path) -> pd.DataFrame
   - Load geojson (json module)
   - For each feature:
     - properties contains fields like area_num_1 (number) and community (name)
     - Use env overrides COMMUNITY_AREA_NUMBER_FIELD and COMMUNITY_AREA_NAME_FIELD
     - Convert community_area to int
     - community_area_name to str
   - Deduplicate by community_area
   - Sort by community_area
   - Return df with columns: community_area (int), community_area_name (str)

3) ensure_community_areas_dim(...)
   - Call ensure_community_areas_geojson(...) first
   - Build df = extract_dim_from_geojson(...)
   - Write df to parquet:
       data/dim/community_areas/community_areas.parquet
   - This guarantees the dim + geojson stay in sync.

NOTE: Do not fetch geometry via /resource/*.json — use the geospatial export endpoint because it returns polygons in GeoJSON.

QUERY LAYER CHANGES (DuckDB)
Update chicago_crime/analytics/queries.py:

A) Continue to provide joined crimes records with names:
- Register:
  crimes = read_parquet('data/lake/crimes/**/*.parquet')
  community_areas = read_parquet('data/dim/community_areas/community_areas.parquet')  (if exists)
- Joined base:
  SELECT c.*, ca.community_area_name
  FROM crimes c
  LEFT JOIN community_areas ca
    ON TRY_CAST(c.community_area AS INTEGER) = ca.community_area

B) Add choropleth aggregation functions:
1) community_area_counts(date_start, date_end, primary_types, district, arrest, domestic) -> DataFrame
   - Return columns:
       community_area (int),
       community_area_name (str, nullable),
       crime_count (int)
   - SQL:
       SELECT TRY_CAST(community_area AS INTEGER) AS community_area,
              COALESCE(ca.community_area_name, CONCAT('CA ', TRY_CAST(community_area AS VARCHAR))) AS community_area_name,
              COUNT(*) AS crime_count
       FROM crimes c
       LEFT JOIN community_areas ca ...
       WHERE ...filters...
       GROUP BY 1,2

2) community_area_arrest_rate(...) -> DataFrame
   - Return columns:
       community_area,
       community_area_name,
       arrest_rate (float 0..1),
       crime_count (int)  # for display / tooltips
   - arrest_rate = SUM(CASE WHEN arrest THEN 1 ELSE 0 END)::DOUBLE / COUNT(*)

C) Provide get_available_community_areas() for dropdown options (from dim parquet if exists).

GEOJSON LOADING FOR PLOTLY
Create chicago_crime/analytics/geo.py:

- load_community_areas_geojson(data_dir) -> dict
  - Reads data/dim/community_areas/community_areas.geojson
  - Returns python dict

- ensure_feature_id_key(geojson, number_field) -> geojson
  - Plotly choropleth_mapbox needs a matching feature id key.
  - If the feature already has properties[number_field], keep it.
  - Ensure each feature has:
      feature["id"] = int(properties[number_field])
    This makes the join easy: featureidkey="id"

- Optionally, build a lightweight dict:
    {community_area_number: community_area_name}
  for hover labels.

DASH APP: ADD CHOROPLETH MAP
Update UI to add:
- A Map Mode toggle: (Auto / Points / Choropleth)
- A Choropleth Metric selector: (Crime Count / Arrest Rate)

AUTO LOGIC
- If map mode == auto:
   - Use Points if (date_range_days <= MAP_MAX_DAYS_POINTS AND filtered_rows <= MAX_MAP_POINTS)
   - Else use Choropleth

CHOROPLETH IMPLEMENTATION
In callbacks:
- Load geojson once on startup (cache in module global or LRU).
- For choropleth, call community_area_counts() or community_area_arrest_rate() depending on metric.
- Use Plotly:
   plotly.express.choropleth_mapbox(
     df,
     geojson=geojson,
     locations="community_area",       # ints
     featureidkey="id",                # because we set feature["id"]
     color="crime_count" OR "arrest_rate",
     hover_name="community_area_name",
     hover_data={"crime_count": True, "arrest_rate": ":.1%"},
     center={"lat": 41.8781, "lon": -87.6298},
     zoom=9,
     mapbox_style="open-street-map"   # no paid token needed
   )
- Handle missing community_area (NULL) by excluding those rows from choropleth aggregation (or mapping them to 0 is not recommended).

POINTS MAP UPDATE
- Keep existing scatter_mapbox behavior for smaller ranges; include hover:
   community_area_name (fallback CA code), primary_type, date, arrest

ADD A CHART
- Keep “Top Community Areas” bar chart:
   - Use community_area_name
   - Based on community_area_counts()

DOWNLOAD CSV
- Ensure CSV export includes:
   community_area, community_area_name

WIRING
- Update scripts/ingest_daily.py:
   - Run ensure_community_areas_dim(max_age_days=DIM_MAX_AGE_DAYS) before the app starts OR before/after crime ingest.
- Update scripts/run_app.py:
   - Best-effort call ensure_community_areas_dim(...) on startup; log warnings, do not crash if fetch fails.

TESTS
1) tests/test_geojson_join_key.py
   - Given a small geojson fixture with properties.area_num_1 strings, ensure ensure_feature_id_key sets feature["id"] as int.

2) tests/test_dim_ingest.py
   - Use a temp geojson file fixture; run extract_dim_from_geojson; validate schema and values.

3) tests/test_choropleth_agg.py
   - Create tiny crimes parquet and community_areas.parquet; run community_area_counts; assert grouping and names.

DOCKER
- Ensure docker-compose mounts ./data into /app/data so cached geojson persists.
- No new services needed.
- App should start even if dims are missing; choropleth shows a helpful error panel: “Community area boundaries not available yet — run ingest.”

README UPDATES
- Explain:
  - GeoJSON caching path
  - How to refresh boundaries: `python -m chicago_crime.ingest.ingest_dimensions --force`
  - How choropleth uses feature["id"] join to `community_area`

QUALITY BAR
- End-to-end runnable.
- Robust error handling.
- Clear logs.
- No TODO placeholders.
- Keep code style consistent with existing project.

Now implement these changes in the repo, producing all new/updated files with correct imports and runnable behavior.